from celery import shared_task
from youtube_crawling.longform_crawler import crawl_channel_videos
import logging, time, os

logger = logging.getLogger(__name__)

@shared_task
def crawl_channels_task():
    channel_urls = [
        "https://www.youtube.com/@%EC%B9%A1%EC%B4%89",
    ]
    export_dir = "./crawling_result_csv/"
    os.makedirs(export_dir, exist_ok=True)

    for url in channel_urls:
        try:
            logger.info(f"ğŸš€ ì±„ë„ ì‹œì‘: {url}")
            
            # í¬ë¡¤ë§ ì‹œì‘ ì „ ì¶©ë¶„í•œ ëŒ€ê¸° ì‹œê°„ í™•ë³´
            logger.info("â³ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
            time.sleep(5)  # 5ì´ˆë¡œ ì¦ê°€
            
            crawl_channel_videos(url, export_dir)
            
            logger.info(f"âœ… ì±„ë„ ì™„ë£Œ: {url}")
            
            # ë‹¤ìŒ ì±„ë„ í¬ë¡¤ë§ ì „ ëŒ€ê¸°
            logger.info("â³ ë‹¤ìŒ ì±„ë„ í¬ë¡¤ë§ ì „ ëŒ€ê¸° ì¤‘...")
            time.sleep(5)  # 5ì´ˆë¡œ ì¦ê°€
            
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ - {url}: {e}")
            logger.error("ìƒì„¸ ì—ëŸ¬:", exc_info=True)
