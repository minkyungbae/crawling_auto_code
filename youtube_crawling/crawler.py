# --------- í”„ë¡œì íŠ¸ì—ì„œ importí•œ ëª©ë¡ ---------------
from .models import YouTubeVideo, YouTubeProduct
from config import settings
# --------- seleniumì—ì„œ importí•œ ëª©ë¡ ---------------
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
# --------- webdriverì—ì„œ importí•œ ëª©ë¡ ---------------
from webdriver_manager.chrome import ChromeDriverManager
from contextlib import contextmanager # ë“œë¼ì´ë²„ ê´€ë¦¬í•˜ëŠ” íƒœê·¸
# --------- ê·¸ ì™¸ í¬ë¡¤ë§ ì½”ë“œë¥¼ ìœ„í•´ importí•œ ëª©ë¡ ---------------
from bs4 import BeautifulSoup
from datetime import datetime
from typing import List, Union, Dict, Optional
from urllib.parse import urlparse, unquote
from slugify import slugify
import pandas as pd
import logging, time, re, json, os, urllib.parse


# ----------------------------- â¬‡ï¸ logging ì„¤ì • -----------------------------

logger = logging.getLogger(__name__)  # logger.info(), logger.warning()ë§Œ ì¨ì•¼í•´ìš©

# --------- driver í•œ ë²ˆìœ¼ë¡œ ì •ì˜ ---------------
@contextmanager
def create_driver():
    options = webdriver.ChromeOptions()
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-infobars")
    options.add_argument("--start-maximized")
    options.add_argument("--disable-notifications")
    options.add_argument('--ignore-certificate-errors')
    options.add_argument('--ignore-ssl-errors')
    # User-Agent ì„¤ì •
    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36')
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    logger.info("ğŸŸ¢ ChromeDriver ì‹¤í–‰")
    try:
        yield driver
    except Exception as e:
        logger.error(f"âŒ WebDriver ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
        raise
    finally:
        driver.quit()
        logger.info("ğŸ›‘ ChromeDriver ì¢…ë£Œ")


# ---------------------- â¬‡ï¸ URL ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜ ì¶”ê°€ ----------------------
def clean_youtube_url(url: str) -> str:
    """YouTube URLì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # URLì—ì„œ 'watch?v=' ë¶€ë¶„ì´ ì¤‘ë³µë˜ëŠ”ì§€ í™•ì¸
        if url.count('watch?v=') > 1:
            # ë§ˆì§€ë§‰ 'watch?v=' ì´í›„ì˜ ë¶€ë¶„ë§Œ ê°€ì ¸ì˜´
            video_id = url.split('watch?v=')[-1]
            return f'https://www.youtube.com/watch?v={video_id}'
        return url
    except Exception as e:
        logger.error(f"âŒ URL ì •ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return url


# ----------------------------- â¬‡ï¸ ìœ íŠœë¸Œ ì±„ë„ì˜ ì˜ìƒ ì „ë¶€ ê°€ì§€ê³  ì˜¤ëŠ” í•¨ìˆ˜ -----------------------------
def get_all_video_ids(driver, channel_url):
    logger.info(f"ğŸ” ì±„ë„ ì˜ìƒ ID ìˆ˜ì§‘ ì‹œì‘: {channel_url}")

    try:
        videos_url = channel_url.rstrip('/') + "/videos"
        driver.get(videos_url)
        time.sleep(5)  # í˜ì´ì§€ ë¡œë”©ì„ ìœ„í•œ ëŒ€ê¸° ì‹œê°„ ì¦ê°€

        video_urls = set()
        last_height = driver.execute_script("return document.documentElement.scrollHeight")
        
        SCROLL_PAUSE_TIME = 3
        MAX_RETRIES = 5
        retries = 0

        while True:
            # ìŠ¤í¬ë¡¤ ë‹¤ìš´
            driver.execute_script("window.scrollTo(0, document.documentElement.scrollHeight);")
            time.sleep(SCROLL_PAUSE_TIME)
            
            # ì˜ìƒ ë§í¬ ìˆ˜ì§‘
            elements = driver.find_elements(By.CSS_SELECTOR, 'a#video-title-link')
            for elem in elements:
                href = elem.get_attribute("href")
                if href and "watch?v=" in href:
                    # URL ì •ë¦¬ í•¨ìˆ˜ ì ìš©
                    cleaned_url = clean_youtube_url(href)
                    video_urls.add(cleaned_url)

            new_height = driver.execute_script("return document.documentElement.scrollHeight")
            if new_height == last_height:
                retries += 1
                if retries >= MAX_RETRIES:
                    break
            else:
                retries = 0
            last_height = new_height

        video_count = len(video_urls)
        if video_count > 0:
            logger.info(f"âœ… ì´ {video_count}ê°œì˜ ì˜ìƒ URL ìˆ˜ì§‘ ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤")

        return list(video_urls)
    except Exception as e:
        logger.error(f"âŒ ì˜ìƒ ID ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return []

# ----------------------------- â¬‡ï¸ elementì˜ text ì¶”ì¶œí•˜ëŠ” ìœ í‹¸ í•¨ìˆ˜ -----------------------------
def safe_get_text(element, default=""):
    try:
        return element.text.strip()
    except Exception:
        return default


# ---------------------- â¬‡ï¸ ì¡°íšŒìˆ˜ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ (ì˜ˆ: ì¡°íšŒìˆ˜ 1,234íšŒ -> 1234) ----------------------
def parse_view_count(text: str) -> int:
    try:
        if not text:
            return 0
        # ì¡°íšŒìˆ˜ì™€ íšŒë¥¼ ì œê±°í•˜ê³  ìˆ«ìì™€ ì†Œìˆ˜ì , ë‹¨ìœ„(ë§Œ)ë§Œ ë‚¨ê¹€
        cleaned = text.replace("ì¡°íšŒìˆ˜", "").replace("íšŒ", "").replace(",", "").strip()
        
        # ë°± ë‹¨ìœ„ê°€ ìˆëŠ” ê²½ìš°
        if "ì²œ" in cleaned:
            number = float(cleaned.replace("ë°±", ""))
            return int(number * 1000)
        # ë§Œ ë‹¨ìœ„ê°€ ìˆëŠ” ê²½ìš°
        elif "ë§Œ" in cleaned:
            number = float(cleaned.replace("ë§Œ", ""))
            return int(number * 10000)
        
        return int(cleaned)
    except ValueError as e:
        logger.warning(f"âš ï¸ ì¡°íšŒìˆ˜ íŒŒì‹± ì‹¤íŒ¨: '{text}', ì´ìœ : {e}")
        return 0


# ----------------------------- â¬‡ï¸ êµ¬ë…ì ìˆ˜ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì í˜•íƒœë¡œ ë³€í™˜ (ì˜ˆ: 1.2ë§Œëª… -> 12000) -----------------------------
def parse_subscriber_count(text: str) -> int:
    try:
        # êµ¬ë…ìì™€ ëª…ì„ ì œê±°í•˜ê³  ìˆ«ìì™€ ì†Œìˆ˜ì , ë‹¨ìœ„(ì²œ, ë§Œ)ë§Œ ë‚¨ê¹€
        text = text.replace("êµ¬ë…ì", "").replace("ëª…", "").replace(",", "").strip()
        
        if "ì²œ" in text:
            number = float(text.replace("ì²œ", ""))
            return int(number * 1000)
        elif "ë§Œ" in text:
            number = float(text.replace("ë§Œ", ""))
            return int(number * 10000)
        
        return int(text)
    except Exception as e:
        logger.warning(f"âš ï¸ êµ¬ë…ì ìˆ˜ íŒŒì‹± ì‹¤íŒ¨: '{text}', ì´ìœ : {e}")
        return 0


# ---------------------- â¬‡ï¸ ë‚ ì§œë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ----------------------
def format_date(date_str: str) -> str:
    try:
        if match := re.search(r'(\d{4})\.\s*(\d{1,2})\.\s*(\d{1,2})\.?', date_str):
            year, month, day = match.groups()
            return f"{year}-{int(month):02d}-{int(day):02d}"
        elif match := re.search(r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼', date_str):
            year, month, day = match.groups()
            return f"{year}-{int(month):02d}-{int(day):02d}"
        elif match := re.search(r'(\d{4})(\d{2})(\d{2})', date_str):
            year, month, day = match.groups()
            return f"{year}-{month}-{day}"
    except Exception as e:
        logger.warning(f"âš ï¸ ë‚ ì§œ í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨: {date_str}, ì—ëŸ¬: {e}")
    return date_str


# ---------------------- â¬‡ï¸ ì„¤ëª…ë€ì˜ ë¶ˆí•„ìš”í•œ ì¤„ë°”ê¿ˆ ì œê±° ----------------------
def clean_description(text: str) -> str:
    if not text:
        return ""
    # ì—°ì†ëœ ì¤„ë°”ê¿ˆì„ í•˜ë‚˜ë¡œ í†µì¼
    text = re.sub(r'\n\s*\n', '\n', text)
    # ì•ë’¤ ê³µë°± ì œê±°
    return text.strip()


# ---------------------- â¬‡ï¸ ì œí’ˆ ê°œìˆ˜ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: 5ê°œ ì œí’ˆ) ----------------------
def parse_product_count(text: str) -> Union[int, None]:
    try:
        if match := re.search(r'(\d+)\s*ê°œ\s*ì œí’ˆ', text):
            return int(match.group(1))
    except:
        logger.warning(f"âš ï¸ ì œí’ˆ ê°œìˆ˜ ëª» ì°¾ì•˜ëŠ”ë…??")
    return None

# ---------------------- â¬‡ï¸ ë”ë³´ê¸° í´ë¦­ ë° ë”ë³´ê¸°ë€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ----------------------
def click_description(driver) -> str:
    try:
        # ìŠ¤í¬ë¡¤ì„ ë‚´ë¦¼ìœ¼ë¡œì¨ ë²„íŠ¼ì´ ë¡œë“œë˜ë„ë¡ ìœ ë„
        body = driver.find_element(By.TAG_NAME, 'body')
        for _ in range(3):
            body.send_keys(Keys.END)
            time.sleep(1)
        # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì‹œë„ (2ê°€ì§€ selector)
        try:
            expand_button = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "#expand"))
            )
            driver.execute_script("arguments[0].click();", expand_button)
            logger.info("ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì„±ê³µ")
        except Exception:
            logger.info("ë”ë³´ê¸° ë²„íŠ¼ ì—†ìŒ ë˜ëŠ” í´ë¦­ ì‹¤íŒ¨, ë¬´ì‹œí•˜ê³  ì§„í–‰")

        selectors = [
            "#description-text-container",
            "#description-inline-expander"
        ]
        for selector in selectors:
            try:
                elem = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, selector))
                )
                desc = elem.text.strip()
                if desc:
                    return desc
            except Exception:
                logger.debug(f"'{selector}'ë¡œ ì„¤ëª…ë€ ì¶”ì¶œ ì‹¤íŒ¨, ë‹¤ìŒ ì‹œë„")
        logger.warning("ë”ë³´ê¸°ë€ì— ì„¤ëª…ì´ ì—†ìŒ")
        return "ë”ë³´ê¸°ë€ì— ì„¤ëª… ì—†ìŒ"
        
    except Exception as e:
        logger.error(f"âŒ ì„¤ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)
        return "ë”ë³´ê¸°ë€ì— ì„¤ëª… ì—†ìŒ"
    
    
#--------------------------------------- ì œí’ˆ ì •ë³´ ì¶”ì¶œ -------------------------------------
def extract_products_from_dom(soup: BeautifulSoup) -> list[dict]:
    products = []
    try:
        # ì œí’ˆ ì„¹ì…˜ ì°¾ê¸°
        product_sections = soup.find_all("ytd-product-metadata-badge-renderer")
        
        if not product_sections:
            # ìƒˆë¡œìš´ YouTube êµ¬ì¡°ì—ì„œ ì œí’ˆ ì •ë³´ ì°¾ê¸°
            product_sections = soup.find_all("ytd-merch-shelf-renderer")
            
        for section in product_sections:
            try:
                # ì œí’ˆ ì´ë¯¸ì§€
                img_tag = section.find("img")
                image_url = img_tag.get("src") if img_tag else None
                
                # ì œí’ˆ ì´ë¦„
                title_tag = section.find(["yt-formatted-string", "span"], class_="product-title") or \
                           section.find("span", {"id": "title"})
                title = title_tag.text.strip() if title_tag else "ì œí’ˆëª… ì—†ìŒ"
                
                # ì œí’ˆ ê°€ê²©
                price_tag = section.find(["yt-formatted-string", "span"], class_="price") or \
                           section.find("span", {"id": "price"})
                price = price_tag.text.strip() if price_tag else None
                
                # ì œí’ˆ ë§í¬
                link_tag = section.find("a")
                link = link_tag.get("href") if link_tag else None
                if link and not link.startswith("http"):
                    link = f"https://www.youtube.com{link}"
                
                products.append({
                    "title": title,
                    "url": link,
                    "price": price,
                    "imageUrl": image_url,
                })
                
            except Exception as e:
                logger.warning(f"ê°œë³„ ì œí’ˆ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                continue
                
        if not products:
            # ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì œí’ˆ ë°ì´í„° ì°¾ê¸° (ê¸°ì¡´ ë°©ì‹)
            script_tags = soup.find_all("script")
            for tag in script_tags:
                if tag.string and "var productsData" in tag.string:
                    try:
                        json_text = tag.string.split("var productsData = ")[1].split(";</script>")[0]
                        product_data = json.loads(json_text)
                        for product in product_data:
                            products.append({
                                "title": product.get("title", "ì—†ìŒ"),
                                "url": product.get("url", "ì—†ìŒ"),
                                "price": product.get("price", "ì—†ìŒ"),
                                "imageUrl": product.get("imageUrl", "ì—†ìŒ"),
                            })
                    except Exception as e:
                        logger.warning(f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
                    break
                    
    except Exception as e:
        logger.error(f"âŒ ì œí’ˆ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
    return products
    

# ---------------------- â¬‡ï¸ ì˜ìƒ ê¸°ë³¸ ì •ë³´: ì œëª©, ì±„ë„ëª…, êµ¬ë…ì ìˆ˜, ì¡°íšŒìˆ˜, ì—…ë¡œë“œì¼, ì œí’ˆ ê°œìˆ˜ ----------------------
def base_youtube_info(driver, video_url: str) -> pd.DataFrame:
    logger.info("Crawling video: %s", video_url)
    today_str = datetime.today().strftime('%Y%m%d')

    try:
        driver.get(video_url)
        # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì‹œê°„ ì¦ê°€ ë° ëª…ì‹œì  ëŒ€ê¸° ì¡°ê±´ ì¶”ê°€
        wait = WebDriverWait(driver, 20)
        
        # ì œí’ˆ ì„¹ì…˜ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        try:
            wait.until(lambda d: d.find_elements(By.CSS_SELECTOR, 
                "ytd-product-metadata-badge-renderer, ytd-merch-shelf-renderer"))
        except:
            logger.info("ì œí’ˆ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
        
        # í˜ì´ì§€ ìŠ¤í¬ë¡¤í•˜ì—¬ ë™ì  ì»¨í…ì¸  ë¡œë“œ
        driver.execute_script("window.scrollTo(0, 400);")
        time.sleep(2)
        
        # ì„¤ëª…ë€ í¼ì¹˜ê¸° ë²„íŠ¼ í´ë¦­ ì‹œë„
        try:
            more_button = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "tp-yt-paper-button#expand")))
            driver.execute_script("arguments[0].click();", more_button)
            time.sleep(1)
        except:
            logger.info("ì„¤ëª…ë€ í¼ì¹˜ê¸° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        soup = BeautifulSoup(driver.page_source, "html.parser")

        # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        video_id = video_url.split("v=")[-1]
        
        # ì œëª© (ì—¬ëŸ¬ ì„ íƒì ì‹œë„)
        title_selectors = [
            "h1.title yt-formatted-string",
            "h1.title",
            "#title h1",
            "#container h1.style-scope.ytd-watch-metadata"
        ]
        title = None
        for selector in title_selectors:
            title_elem = soup.select_one(selector)
            if title_elem:
                title = title_elem.get_text(strip=True)
                if title:
                    break
        title = title or "ì œëª© ì—†ìŒ"
        logger.info(f"ì œëª©: {title}")

        # ì±„ë„ëª… (ì—¬ëŸ¬ ì„ íƒì ì‹œë„)
        channel_selectors = [
            "ytd-channel-name yt-formatted-string#text a",
            "ytd-channel-name a",
            "#channel-name a"
        ]
        channel_name = None
        for selector in channel_selectors:
            channel_tag = soup.select_one(selector)
            if channel_tag:
                channel_name = channel_tag.text.strip()
                break
        channel_name = channel_name or "ì±„ë„ ì—†ìŒ"

        # êµ¬ë…ì ìˆ˜
        sub_selectors = [
            "yt-formatted-string#owner-sub-count",
            "#subscriber-count"
        ]
        subscriber_count = None
        for selector in sub_selectors:
            sub_tag = soup.select_one(selector)
            if sub_tag:
                subscriber_count = sub_tag.text.strip()
                break
        subscriber_count = subscriber_count or "êµ¬ë…ì ìˆ˜ ì—†ìŒ"

        # ì¡°íšŒìˆ˜
        view_selectors = [
            "span.view-count",
            "#view-count",
            "ytd-video-view-count-renderer"
        ]
        view_count = None
        for selector in view_selectors:
            view_tag = soup.select_one(selector)
            if view_tag:
                view_count = view_tag.text.strip()
                break
        view_count = view_count or "ì¡°íšŒìˆ˜ ì—†ìŒ"

        # ì—…ë¡œë“œì¼
        date_selectors = [
            "#info-strings yt-formatted-string",
            "#upload-info .date",
            "ytd-video-primary-info-renderer yt-formatted-string.ytd-video-primary-info-renderer:not([id])"
        ]
        upload_date = None
        for selector in date_selectors:
            date_tag = soup.select_one(selector)
            if date_tag:
                upload_date = date_tag.text.strip()
                break
        upload_date = upload_date or "ë‚ ì§œ ì—†ìŒ"

        # ì„¤ëª…ë€
        desc_selectors = [
            "ytd-expander#description yt-formatted-string",
            "#description",
            "#description-inline-expander",
            "#description-text-container"
        ]
        description = None
        for selector in desc_selectors:
            desc_tag = soup.select_one(selector)
            if desc_tag:
                description = desc_tag.text.strip()
                if description:
                    break
        description = description or "ì„¤ëª… ì—†ìŒ"
        logger.info(f"ì„¤ëª… ê¸¸ì´: {len(description)} ê¸€ì")

        # ì œí’ˆ ì¶”ì¶œ
        products = extract_products_from_dom(soup)
        product_count = len(products)

        # ê¸°ë³¸ ë°ì´í„° ì„¸íŠ¸
        base_data = {
            "youtube_id": video_id,
            "title": title,
            "channel_name": channel_name,
            "subscribers": subscriber_count,
            "view_count": view_count,
            "upload_date": upload_date,
            "extracted_date": today_str,
            "video_url": video_url,
            "description": description,
            "product_count": product_count,
            "products": products
        }

        logger.info(f"âœ… ì˜ìƒ ì •ë³´ ë° ì œí’ˆ {product_count}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
        return pd.DataFrame([base_data])
    
    except Exception as e:
        logger.error(f"âŒ base_youtube_info ì˜ˆì™¸: {e}", exc_info=True)
        return pd.DataFrame()

# ----------------------------------------------- â¬‡ï¸ ìœ íŠœë¸Œ ì˜ìƒ URL ì ‘ì† í›„ ë°ì´í„° ìˆ˜ì§‘ ìˆ˜í–‰ -----------------------------------------------

def collect_video_data(driver, video_id: str, index: int = None, total: int = None) -> pd.DataFrame:
    # URL ì •ë¦¬
    base_url = clean_youtube_url(f"https://www.youtube.com/watch?v={video_id}")
    
    try:
        driver.get(base_url)
        if index is not None and total is not None:
            logger.info(f"\nğŸ“¹ ({index}/{total}) í¬ë¡¤ë§ ì¤‘: {video_id}")

        df = base_youtube_info(driver, base_url)

        logger.info(f"ğŸ“¦ ìˆ˜ì§‘ëœ ì œí’ˆ ê°œìˆ˜: {len(df)}")
        if df.empty:
            logger.warning(f"âš ï¸ ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ ìˆìŒ: {video_id}")

        return df
    
    except Exception as e:
            logger.error(f"âŒ ì˜ˆì™¸ ë°œìƒ - collect_video_data(): {video_id} | ì—ëŸ¬: {e}")
            return None

# ------------------------------------- â¬‡ï¸ í¬ë¡¤ë§ëœ ìœ íŠœë¸Œ ì˜ìƒì„ ì¡°íšŒí•˜ê³  ìˆ˜ì •í•˜ëŠ” ì½”ë“œ ------------------------------
def update_youtube_data_to_db(dataframe: pd.DataFrame) -> int:
    if dataframe.empty:
        return 0

    video_id = dataframe.iloc[0]['video_id']
    
    try:
        video = YouTubeVideo.objects.get(video_id=video_id)
        row = dataframe.iloc[0]

        # ê¸°ì¡´ ì˜ìƒ ì •ë³´ ì—…ë°ì´íŠ¸
        video.extracted_date = row['extracted_date']
        video.upload_date = row['upload_date']
        video.channel_name = row['channel_name']
        video.subscriber_count = row['subscriber_count']
        video.video_url = row['video_url']
        video.title = row['title']
        video.view_count = row['view_count']
        video.product_count = row['product_count']
        video.description = row['description']
        video.save()

        # ê¸°ì¡´ ì œí’ˆ ì •ë³´ ì‚­ì œ í›„ ìƒˆë¡œ ì €ì¥
        video.products.all().delete()

        # pd.DataFrame == dataframe
        for _, row in dataframe.iterrows():
            product_name = row.get('product_name')
            if product_name and pd.notna(product_name):
                YouTubeProduct.objects.create(
                    video=video,
                    product_image_link=row.get('product_image_link'),
                    product_name=product_name,
                    product_price=row.get('product_price'),
                    product_link=row.get('product_link'),
                )
        logger.info(f"ğŸ” ì˜ìƒ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {video_id}")
        return 1

    except YouTubeVideo.DoesNotExist:
        logger.warning(f"âŒ í•´ë‹¹ video_idì— ëŒ€í•œ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤: {video_id}")
        return 0

# ------------------------------------- â¬‡ï¸ ì±„ë„ URLì—ì„œ ê³ ìœ í•œ ID ì¶”ì¶œ (ì˜ˆ: UCxxxx ë˜ëŠ” @handle í˜•ì‹) ------------------------------
def get_channel_id_from_url(channel_url):
    parsed = urlparse(channel_url)
    parts = parsed.path.strip("/").split("/")
    return parts[-1] if parts else "unknown_channel"

# ------------------------------------- â¬‡ï¸ ì±„ë„ URLì—ì„œ ê³ ìœ í•œ ID ì¶”ì¶œ (ì˜ˆ: UCxxxx ë˜ëŠ” @handle í˜•ì‹) ------------------------------
def get_channel_name(driver, channel_url):
    """
    ì±„ë„ ì´ë¦„ì„ YouTube ì±„ë„ í˜ì´ì§€ì—ì„œ ê°€ì ¸ì˜´.
    """
    driver.get(channel_url)
    driver.implicitly_wait(5)
    try:
        title_element = driver.find_element("xpath", '//meta[@property="og:title"]')
        channel_name = title_element.get_attribute("content")
        return slugify(channel_name)  # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ slugify ì²˜ë¦¬
    except Exception as e:
        logger.warning(f"âš ï¸ ì±„ë„ëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return "unknown_channel"
    
# ------------------------------------- â¬‡ï¸ ì—‘ì…€ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ ------------------------------
def save_to_excel(df: pd.DataFrame, file_path: str):
    try:
        today_str = datetime.now().strftime("%Y%m%d")
        if file_path.lower().endswith(".xlsx"):
            file_path = file_path[:-5] + f"_{today_str}.xlsx"
        else:
            file_path = file_path + f"_{today_str}.xlsx"

        df.to_excel(file_path, index=False)
        logger.info(f"ğŸ’¾ ì—‘ì…€ ì €ì¥ ì™„ë£Œ: {file_path}")
    except Exception as e:
        logger.error(f"âŒ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)

# ------------------------------------- â¬‡ï¸ DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ ------------------------------
def save_to_db(data: dict):
    from django.db import transaction

    if data.empty:
        logger.warning("âš ï¸ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    failed_ids = []

    with transaction.atomic():
        try:
            # DataFrameì˜ ì²« ë²ˆì§¸ í–‰ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            data_dict = data.iloc[0].to_dict()
            video_id = data_dict.get("youtube_id")
            if not video_id:
                logger.warning("âš ï¸ video_id ì—†ìŒ, ì €ì¥ ë¶ˆê°€")
                return
            
            # ë‚ ì§œ í˜•ì‹ ë³€í™˜
            extracted_date = format_date(data_dict.get("extracted_date", ""))
            upload_date = format_date(data_dict.get("upload_date", ""))
            
            # êµ¬ë…ì ìˆ˜ì™€ ì¡°íšŒìˆ˜ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜
            subscriber_count = parse_subscriber_count(data_dict.get("subscribers", "0"))
            view_count = parse_view_count(data_dict.get("view_count", "0"))
            
            # ì„¤ëª…ë€ ì •ë¦¬
            description = clean_description(data_dict.get("description", ""))
            
            video_data = {
                "extracted_date": extracted_date,
                "upload_date": upload_date,
                "channel_name": data_dict.get("channel_name"),
                "subscriber_count": subscriber_count,
                "title": data_dict.get("title"),
                "view_count": view_count,
                "video_url": data_dict.get("video_url"),
                "product_count": data_dict.get("product_count", 0),
                "description": description,
            }

            video_obj = YouTubeVideo.objects.filter(video_id=video_id).first()

            if video_obj:
                # ë³€ê²½ëœ í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                has_changes = any(
                    getattr(video_obj, field) != value
                    for field, value in video_data.items()
                )
                if has_changes:
                    for field, value in video_data.items():
                        setattr(video_obj, field, value)
                    video_obj.save()
                    logger.info(f"DB ì—…ë°ì´íŠ¸ ì™„ë£Œ: {video_id}")
                else:
                    logger.info(f"ë³€ê²½ ì—†ìŒ: {video_id}")
            else:
                video_obj = YouTubeVideo.objects.create(video_id=video_id, **video_data)
                logger.info(f"DB ì €ì¥ ì™„ë£Œ: {video_id}")

            # ì œí’ˆ ì €ì¥
            products = data_dict.get("products", [])
            updated_count = 0
            created_count = 0
            
            for p in products:
                if isinstance(p, dict):
                    product, created = YouTubeProduct.objects.update_or_create(
                        video=video_obj,
                        product_name=p.get("name", "ì œí’ˆ ì—†ìŒ"),
                        defaults={
                            "product_price": p.get("price"),
                            "product_image_link": p.get("image"),
                            "product_link": p.get("link")
                        }
                    )
                    if created:
                        created_count += 1
                    else:
                        updated_count += 1
                        
            logger.info(f"âœ… ì œí’ˆ ì •ë³´ ì²˜ë¦¬ ì™„ë£Œ - ìƒì„±: {created_count}ê°œ, ì—…ë°ì´íŠ¸: {updated_count}ê°œ (video_id: {video_id})")

        except Exception as e:
            logger.error(f"âŒ ì €ì¥ ì‹¤íŒ¨ - video_id: {video_id} | ì—ëŸ¬: {e}")
            failed_ids.append(video_id)
        
    # ì‹¤íŒ¨í•œ video_id íŒŒì¼ë¡œ ì €ì¥
    if failed_ids:
        with open("logs/failed_ids.txt", "w") as f:
            for vid in failed_ids:
                f.write(f"{vid}\n")
        logger.warning(f"âš ï¸ ì €ì¥ ì‹¤íŒ¨í•œ video_id {len(failed_ids)}ê°œ ì €ì¥ ì™„ë£Œ: failed_ids.txt")


# ------------------------------------- â¬‡ï¸ ìœ íŠœë¸Œ ì±„ë„ì˜ ì „ì²´ í¬ë¡¤ë§ì„ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜ ------------------------------
def crawl_channel_videos(channel_url: str, save_path: str):
    with create_driver() as driver:
        video_ids = get_all_video_ids(driver, channel_url)

        total = len(video_ids)
        if total == 0:
            logger.warning("âŒ ì±„ë„ì—ì„œ ìˆ˜ì§‘ëœ ì˜ìƒ IDê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        logger.info(f"ì´ {total}ê°œ ì˜ìƒ í¬ë¡¤ë§ ì‹œì‘")
        all_data = pd.DataFrame()

        for i, video_id in enumerate(video_ids, start=1):
            try:
                df = collect_video_data(driver, video_id, i, total)
                if df is not None and not df.empty:
                    save_to_db(df)
            except Exception as e:
                logger.error(f"âŒ ì˜ìƒ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ: {video_id}, ì—ëŸ¬: {e}", exc_info=True)

        if not all_data.empty:
            save_to_db(all_data)
            save_to_excel(all_data, save_path)
        else:
            logger.warning("âš ï¸ í¬ë¡¤ë§ ê²°ê³¼ ë°ì´í„° ì—†ìŒ")


# ë©”ì¸ ì‹¤í–‰ë¶€
if __name__ == "__main__":

    logging.basicConfig(level=logging.INFO)

    channel_urls = [
        "https://www.youtube.com/@yegulyegul8256",
        "https://www.youtube.com/@%EC%B9%A1%EC%B4%89",
    ]
    
    export_dir = "exports"
    if not os.path.exists(export_dir):
        os.makedirs(export_dir)

    for channel_url in channel_urls:
        try:
            logger.info(f"ğŸš€ ì±„ë„ í¬ë¡¤ë§ ì‹œì‘: {channel_url}")

            today_str = datetime.datetime.now().strftime("%Y%m%d")
            channel_name = urllib.parse.unquote(channel_url.split("/")[-1])
            save_path = os.path.join(export_dir,f"{channel_name}_{today_str}.xlsx")

            crawl_channel_videos(channel_url, save_path)
            logger.info(f"âœ… ì±„ë„ í¬ë¡¤ë§ ì™„ë£Œ: {channel_url}")

        except Exception as e:
            logger.warning(f"âŒ ì±„ë„ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {channel_url} - {e}")
        
        time.sleep(3)  # ğŸ”½ ê° ì±„ë„ ê°„ 3ì´ˆ ì‰¬ì—ˆë‹¤ê°€ ë‹¤ìŒ ì±„ë„ ì‹¤í–‰
